{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c863d0-6ecb-4d04-b06e-3283c91fc8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/ml/workspace/baseline')\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from datasets import load_from_disk, load_dataset\n",
    "from DPR_train import BertEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a2106bb-f5fe-4cb9-a28c-f25428a14cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_kor_v1 (/opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/92f88eedc7d67b3f38389e8682eabe68caa450442cc4f7370a27873dbc045fe4)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "dataset_KLUE = load_from_disk('/opt/ml/input/data/data/train_dataset')\n",
    "validate_dataset = load_dataset('squad_kor_v1')['validation']# dataset_KLUE['validation']\n",
    "q_seqs = tokenizer(validate_dataset['question'], \n",
    "                    padding='max_length', \n",
    "                    truncation=True, \n",
    "                    return_tensors='pt')\n",
    "p_seqs = tokenizer(validate_dataset['context'], \n",
    "                    padding='max_length', \n",
    "                    truncation=True, \n",
    "                    return_tensors='pt')\n",
    "valid_dataset = TensorDataset(p_seqs['input_ids'], p_seqs['token_type_ids'], p_seqs['attention_mask'], \n",
    "                             q_seqs['input_ids'], q_seqs['token_type_ids'], q_seqs['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9ba3a89-ce81-41b7-bc62-5484551e31d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU enabled\n"
     ]
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained('bert-base-multilingual-cased')\n",
    "# p_model = BertEncoder.from_pretrained('/opt/ml/models/DPR_models/q_encoder')\n",
    "p_model = BertEncoder(model_config)\n",
    "state_dict = torch.load('/opt/ml/models/DPR/p_encoder.bin')\n",
    "p_model.load_state_dict(state_dict)\n",
    "# q_model = BertEncoder.from_pretrained('/opt/ml/models/DPR_models/p_encoder')\n",
    "q_model = BertEncoder(model_config)\n",
    "state_dict = torch.load('/opt/ml/models/DPR/q_encoder.bin')\n",
    "q_model.load_state_dict(state_dict)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    p_model.cuda()\n",
    "    q_model.cuda()\n",
    "    print('GPU enabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eac46dc-3530-40f7-8280-8ea241da6924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d76a4f56eba455aa5482c7b796d33c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=145.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ae21725f1a4555867dc2697ad6314d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5774.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'acc/top_1': 0.05767232421198476, 'acc/top_5': 0.2684447523380672, 'acc/top_10': 0.42570142015933493, 'acc/top_20': 0.5753377208174576} 5774\n"
     ]
    }
   ],
   "source": [
    "valid_loader = DataLoader(valid_dataset, 40)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # evaluation\n",
    "    print('let\\'s eval')\n",
    "\n",
    "    p_model.eval()\n",
    "    q_model.eval()\n",
    "\n",
    "    p_outputs = []\n",
    "    q_outputs = []\n",
    "\n",
    "    for batch in tqdm(valid_loader):\n",
    "        batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "        p_inputs = {'input_ids' : batch[0],\n",
    "                    'token_type_ids' : batch[1],\n",
    "                    'attention_mask' : batch[2]\n",
    "                }\n",
    "\n",
    "        q_inputs = {'input_ids' : batch[3],\n",
    "                    'token_type_ids' : batch[4],\n",
    "                    'attention_mask' : batch[5]\n",
    "                }\n",
    "\n",
    "        p_outputs.append(p_model(**p_inputs).cpu().numpy())\n",
    "        q_outputs.append(q_model(**q_inputs).cpu().numpy())\n",
    "\n",
    "    len_vector = p_outputs[0].shape[-1]\n",
    "    tmp_embedding = np.array(p_outputs[:-1]).reshape((-1, len_vector))\n",
    "    p_outputs = np.concatenate((tmp_embedding, p_outputs[-1]), axis=0)\n",
    "\n",
    "    len_vector = q_outputs[0].shape[-1]\n",
    "    tmp_embedding = np.array(q_outputs[:-1]).reshape((-1, len_vector))\n",
    "    q_outputs = np.concatenate((tmp_embedding, q_outputs[-1]), axis=0)\n",
    "\n",
    "    sim_scores = np.dot(q_outputs, p_outputs.T)\n",
    "    sorted_scores = np.argsort(sim_scores, axis=1)\n",
    "\n",
    "    top_1_score, top_5_score, top_10_score, top_20_score = 0, 0, 0, 0\n",
    "\n",
    "    for idx in tqdm(range(len(valid_dataset))):\n",
    "        if idx in sorted_scores[idx][:-2:-1]: top_1_score += 1\n",
    "        if idx in sorted_scores[idx][:-6:-1]: top_5_score += 1\n",
    "        if idx in sorted_scores[idx][:-11:-1]: top_10_score += 1\n",
    "        if idx in sorted_scores[idx][:-21:-1]: top_20_score += 1\n",
    "\n",
    "    top_1_score, top_5_score, top_10_score, top_20_score = top_1_score / len(valid_dataset), \\\n",
    "                                                            top_5_score / len(valid_dataset), \\\n",
    "                                                            top_10_score / len(valid_dataset), \\\n",
    "                                                            top_20_score / len(valid_dataset) \\\n",
    "\n",
    "    print({'acc/top_1': top_1_score, 'acc/top_5': top_5_score, \n",
    "                'acc/top_10': top_10_score, 'acc/top_20': top_20_score},  len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10037e-8cdc-4e39-a70c-75aa7a024c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
